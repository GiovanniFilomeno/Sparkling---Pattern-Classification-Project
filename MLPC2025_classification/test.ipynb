{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a658fa15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% 0 – CONFIG                       ★★★ EDITA SOLO QUI ★★★\n",
    "from pathlib import Path\n",
    "from scipy.special import expit               # logistic\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "ANN_PATH   = Path(\"annotations.csv\")     # ground‑truth\n",
    "META_PATH  = Path(\"metadata.csv\")        # start_time_s / end_time_s\n",
    "LABEL_DIR  = Path(\"labels\")              # *.npz con prediction LF\n",
    "FEAT_DIR   = Path(\"audio_features\")      # *.npz con melspectrogram\n",
    "OUT_DIR    = Path(\"eval_out\")            # dove salvare i risultati\n",
    "\n",
    "SR_DEFAULT   = 32_000     # sample‑rate se mancante\n",
    "HOP_DEFAULT  = 512        # hop_length se mancante\n",
    "IOU_GT_RATIO = 0.3        # minimo 30 % del GT coperto → TP\n",
    "MERGE_GAP    = 0.30       # unisci segmenti LF con gap < 300 ms\n",
    "ENERGY_DB_TH = -50.0      # soglia dB per dire «udibile»\n",
    "\n",
    "ENERGY_USE_WAV = False   # False = usa mel-spectrogram, True = ricarica .mp3\n",
    "MI_N_FRAMES    = 15_000  # campioni max/usati per Mutual-Information\n",
    "\n",
    "OUT_DIR.mkdir(exist_ok=True)\n",
    "print(\"Percorsi impostati ✅\")\n",
    "\n",
    "# %% 1 – IMPORT STANDARD\n",
    "import ast, json, math, itertools\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from intervaltree import Interval, IntervalTree\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# %% 2 – CARICA ANNOTAZIONI + METADATA, NORMALIZZA\n",
    "ann = pd.read_csv(ANN_PATH)\n",
    "ann[\"categories\"] = ann[\"categories\"].apply(ast.literal_eval)\n",
    "ann[\"categories\"] = ann[\"categories\"].apply(lambda L: [c.lower().strip() for c in L])\n",
    "\n",
    "if META_PATH.exists():\n",
    "    meta = pd.read_csv(META_PATH, usecols=[\"filename\", \"start_time_s\", \"end_time_s\"])\n",
    "    ann = ann.merge(meta, on=\"filename\", how=\"left\")\n",
    "    ann[\"onset\"]  = ann[\"onset\"]  - ann[\"start_time_s\"].fillna(0)\n",
    "    ann[\"offset\"] = ann[\"offset\"] - ann[\"start_time_s\"].fillna(0)\n",
    "else:\n",
    "    ann[\"start_time_s\"] = 0.0\n",
    "\n",
    "# rimuovi intervalli nulli / negativi\n",
    "ann = ann[ann[\"onset\"] < ann[\"offset\"]]\n",
    "ann[\"idx\"] = ann[\"filename\"].str.replace(\".mp3\", \"\", regex=False)\n",
    "\n",
    "CLASSES = sorted({c for cats in ann[\"categories\"] for c in cats})\n",
    "print(f\"GT validi: {len(ann)}, clip: {ann['idx'].nunique()}, classi: {len(CLASSES)}\")\n",
    "\n",
    "# %% 3 – HELPER FUNZIONI\n",
    "\n",
    "def covers_gt(pred, gt, thr=IOU_GT_RATIO):\n",
    "    inter = max(0, min(pred[1], gt[1]) - max(pred[0], gt[0]))\n",
    "    return inter / (gt[1]-gt[0]) >= thr\n",
    "\n",
    "\n",
    "def merge_segments(segs, gap=MERGE_GAP):\n",
    "    \"\"\"segs = list[(start,end)] già ordinati; merge se gap<gap\"\"\"\n",
    "    if not segs:\n",
    "        return []\n",
    "    merged = [list(segs[0])]\n",
    "    for a, b in segs[1:]:\n",
    "        if a - merged[-1][1] <= gap:\n",
    "            merged[-1][1] = max(merged[-1][1], b)\n",
    "        else:\n",
    "            merged.append([a, b])\n",
    "    return [tuple(s) for s in merged]\n",
    "\n",
    "\n",
    "def frames_to_segments(mask: np.ndarray, sr: int, hop: int):\n",
    "    \"\"\"Convert a 1‑D binary/probability mask (per frame) into (start,end) segments in **seconds**.\"\"\"\n",
    "    onsets = np.where(mask[:-1] <= 0)[0] + 1  # start after zero→nonzero\n",
    "    onsets = np.insert(onsets, 0, 0) if mask[0] > 0 else onsets\n",
    "    offsets = np.where(mask[1:] <= 0)[0] + 1  # first zero after nonzero\n",
    "    offsets = np.append(offsets, len(mask)) if mask[-1] > 0 else offsets\n",
    "    return [(o * hop / sr, off * hop / sr) for o, off in zip(onsets, offsets) if off > o]\n",
    "\n",
    "\n",
    "def load_pred_segments(path, clip_len, start_shift=0.0, sr=SR_DEFAULT, hop=HOP_DEFAULT):\n",
    "    \"\"\"\n",
    "    Restituisce (segments, class) già:\n",
    "      • convertiti in secondi (se erano frame)\n",
    "      • traslati di -start_shift (clip‑relativi)\n",
    "      • filtrati fuori dal range [0, clip_len]\n",
    "      • uniti con gap < MERGE_GAP\n",
    "    \"\"\"\n",
    "    data = np.load(path, allow_pickle=True)\n",
    "    segs_by_cat = defaultdict(list)\n",
    "\n",
    "    for cls in data.files:\n",
    "        arr = np.asarray(data[cls], dtype=float)\n",
    "        cls_norm = cls.strip().lower()\n",
    "\n",
    "                # ───────── decodifica formato ─────────\n",
    "        if arr.ndim == 2 and arr.shape[1] in {2,3}:   # (N,2) o (N,3)\n",
    "            if arr.shape[1] == 3:                     # probabilità per frame\n",
    "                mask = arr[:, 0]                      # usa primo canale p(event)\n",
    "                if mask.max() <= 0:\n",
    "                    continue\n",
    "                cand = frames_to_segments(mask, sr, hop)\n",
    "            else:                                     # (N,2)\n",
    "                is_frame = arr.max() > clip_len * 10\n",
    "                cand = [(tuple(s * hop / sr) if is_frame else tuple(s)) for s in arr]\n",
    "\n",
    "            for seg in cand:\n",
    "                seg = (seg[0] - start_shift, seg[1] - start_shift)\n",
    "                if seg[1] <= 0 or seg[0] >= clip_len:\n",
    "                    continue\n",
    "                segs_by_cat[cls_norm].append(seg)\n",
    "\n",
    "        elif arr.ndim in {1, 2} and arr.shape[-1] == 1:  # mask per frame (N,1) o (N,)\n",
    "            mask = arr.squeeze()\n",
    "            if mask.max() <= 0:\n",
    "                continue\n",
    "            for seg in frames_to_segments(mask, sr, hop):\n",
    "                seg = (seg[0] - start_shift, seg[1] - start_shift)\n",
    "                if seg[1] <= 0 or seg[0] >= clip_len:\n",
    "                    continue\n",
    "                segs_by_cat[cls_norm].append(seg)\n",
    "        else:\n",
    "            print(\"⚠️ forma non gestita:\", cls, arr.shape)\n",
    "            print(\"⚠️ forma non gestita:\", cls, arr.shape)\n",
    "\n",
    "    # merge + restituisci\n",
    "    segs_final, cats_final = [], []\n",
    "    for cat, lst in segs_by_cat.items():\n",
    "        lst.sort()\n",
    "        for m in merge_segments(lst):\n",
    "            segs_final.append(m); cats_final.append(cat)\n",
    "    return segs_final, cats_final\n",
    "\n",
    "\n",
    "# ——— energia in dB di un segmento ———\n",
    "def segment_energy_db(mel, seg, hop, sr):\n",
    "    a,b = int(seg[0]*sr/hop), int(seg[1]*sr/hop)\n",
    "    # mel: (T, F) log-magnitude;  potenza media → dB\n",
    "    e = mel[a:b].mean()\n",
    "    return 10*np.log10(max(e, 1e-12))\n",
    "\n",
    "# ——— ricava MFCC+ZCR frame-positivi/negativi per MI ———\n",
    "def collect_features_for_mi(feat, lbl_mask, max_n=MI_N_FRAMES):\n",
    "    X = np.hstack([feat['mfcc'], feat['zerocrossingrate']])\n",
    "    y = lbl_mask.astype(int)\n",
    "    # bilancia le classi e sottocampiona\n",
    "    pos_idx = np.where(y==1)[0]\n",
    "    neg_idx = np.where(y==0)[0]\n",
    "    n = min(max_n//2, len(pos_idx), len(neg_idx))\n",
    "    keep = np.concatenate([np.random.choice(pos_idx,n,False),\n",
    "                           np.random.choice(neg_idx,n,False)])\n",
    "    return X[keep], y[keep]\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# %% 4 – LOOP DI VALUTAZIONE\n",
    "# stats = {c: dict(TP=0, FP=0, FN=0) for c in CLASSES}\n",
    "stats = {c: dict(TP=0, FP=0, FN=0,\n",
    "                 TP_aud=0, TP_sil=0,\n",
    "                 FN_aud=0, FN_sil=0) for c in CLASSES}\n",
    "mi_store = {c: [] for c in CLASSES}     # raccolta feature→MI\n",
    "\n",
    "\n",
    "groups = ann.groupby(\"idx\")\n",
    "for idx, gt_rows in tqdm(groups, desc=\"eval\", unit=\"file\"):\n",
    "    start_sec = float(gt_rows[\"start_time_s\"].iloc[0])\n",
    "\n",
    "    # durata clip in secondi dal feature file\n",
    "    feat_path = FEAT_DIR / f\"{idx}.npz\"\n",
    "    if not feat_path.exists():\n",
    "        continue  # manca feature → salta clip\n",
    "    feat = np.load(feat_path, allow_pickle=True)\n",
    "\n",
    "    hop = int(feat.get(\"hop_length\", HOP_DEFAULT))\n",
    "    sr  = int(feat.get(\"sample_rate\",  SR_DEFAULT))\n",
    "    n_frames = feat[\"melspectrogram\"].shape[0]\n",
    "    clip_len = n_frames * hop / sr\n",
    "    tree = defaultdict(IntervalTree)\n",
    "\n",
    "    mel = feat['melspectrogram']   # shape (T, F)\n",
    "\n",
    "    segs_pred, cats_pred = load_pred_segments(\n",
    "        LABEL_DIR / f\"{idx}_labels.npz\",\n",
    "        clip_len=clip_len,\n",
    "        start_shift=start_sec,\n",
    "        sr=sr, hop=hop,\n",
    "    )\n",
    "\n",
    "    wav_energy = {}     # (begin,end) -> audible?\n",
    "    for r in gt_rows.itertuples():\n",
    "        for cat in r.categories:\n",
    "            a,b = max(0,r.onset), max(0,r.offset)\n",
    "            if b<=a or a>=clip_len: continue\n",
    "            aud = segment_energy_db(mel,(a,b),hop,sr) > ENERGY_DB_TH\n",
    "            tree[cat].add(Interval(a,min(b,clip_len),{\"aud\":aud}))\n",
    "            wav_energy[(a,b,cat)] = aud\n",
    "\n",
    "\n",
    "    # costruisci IntervalTree GT per classe\n",
    "    # tree = defaultdict(IntervalTree)\n",
    "    # for r in gt_rows.itertuples():\n",
    "    #     for cat in r.categories:\n",
    "    #         a, b = max(0, r.onset), max(0, r.offset)\n",
    "    #         if b <= a or a >= clip_len:\n",
    "    #             continue\n",
    "    #         tree[cat].add(Interval(a, min(b, clip_len)))\n",
    "\n",
    "    matched = {c: set() for c in CLASSES}\n",
    "\n",
    "    for cat in CLASSES:\n",
    "        # maschera frame GT “positivi” per quella classe\n",
    "        mask = np.zeros(n_frames, dtype=bool)\n",
    "        for iv in tree.get(cat, []):\n",
    "            a,b = int(iv.begin*sr/hop), int(iv.end*sr/hop)\n",
    "            mask[a:b] = True\n",
    "        if mask.any():\n",
    "            X, y = collect_features_for_mi(feat, mask)\n",
    "            mi_store[cat].append((X,y))\n",
    "\n",
    "    for seg, cat in zip(segs_pred, cats_pred):\n",
    "        if cat not in stats:\n",
    "            continue\n",
    "        overlaps = [iv for iv in tree[cat].overlap(*seg) if covers_gt(seg, (iv.begin, iv.end))]\n",
    "        if overlaps:\n",
    "            aud_gt = overlaps[0].data['aud']\n",
    "            key = \"TP_aud\" if aud_gt else \"TP_sil\"\n",
    "            stats[cat][key] += 1\n",
    "            stats[cat][\"TP\"] += 1                # ← ripristina\n",
    "            matched[cat].add((overlaps[0].begin, overlaps[0].end))\n",
    "        else:\n",
    "            stats[cat][\"FP\"] += 1\n",
    "\n",
    "    # for cat, tr in tree.items():\n",
    "    #     stats[cat][\"FN\"] += len(tr) - len(matched[cat])\n",
    "\n",
    "    for cat,tr in tree.items():\n",
    "        for iv in tr:\n",
    "            if (iv.begin,iv.end) not in matched[cat]:\n",
    "                k = \"FN_aud\" if iv.data['aud'] else \"FN_sil\"\n",
    "                stats[cat][k] += 1\n",
    "                stats[cat][\"FN\"] += 1\n",
    "\n",
    "\n",
    "# %% 5 – BUILD METRICS DF – BUILD METRICS DF\n",
    "rows = []\n",
    "for cat,s in stats.items():\n",
    "    tp,fp,fn = s[\"TP\"],s[\"FP\"],s[\"FN\"]\n",
    "    prec = tp/(tp+fp+1e-9); rec = tp/(tp+fn+1e-9)\n",
    "    f1 = 2*prec*rec/(prec+rec+1e-9)\n",
    "    rows.append({**{\"class\":cat,\"precision\":prec,\"recall\":rec,\"f1\":f1}, **s})\n",
    "df = pd.DataFrame(rows).sort_values(\"class\")\n",
    "df.to_csv(OUT_DIR/\"results.csv\", index=False)\n",
    "print(\"✓ Salvato results.csv\")\n",
    "\n",
    "# Mutual-Information feature ranking\n",
    "mi_rows = []\n",
    "for cat,pairs in mi_store.items():\n",
    "    if not pairs: continue\n",
    "    X = np.vstack([p[0] for p in pairs])\n",
    "    y = np.hstack([p[1] for p in pairs])\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    mi = mutual_info_classif(X, y, random_state=0)\n",
    "    for k,val in enumerate(mi):\n",
    "        mi_rows.append({\"class\":cat, \"feat_idx\":k, \"MI\":val})\n",
    "pd.DataFrame(mi_rows).to_csv(OUT_DIR/\"mutual_info.csv\", index=False)\n",
    "\n",
    "\n",
    "# %% 6 – AGGREGATI\n",
    "macro_f1 = df[\"f1\"].mean()\n",
    "micro_tp = df.TP.sum(); micro_fp = df.FP.sum(); micro_fn = df.FN.sum()\n",
    "micro_p = micro_tp/(micro_tp+micro_fp+1e-9)\n",
    "micro_r = micro_tp/(micro_tp+micro_fn+1e-9)\n",
    "micro_f1 = 2*micro_p*micro_r/(micro_p+micro_r+1e-9)\n",
    "\n",
    "with open(OUT_DIR/\"overall_metrics.txt\",\"w\") as f:\n",
    "    f.write(f\"Macro-F1  : {macro_f1:.4f}\\n\");\n",
    "    f.write(f\"Micro-F1  : {micro_f1:.4f}\\n\");\n",
    "    f.write(f\"Micro-P   : {micro_p:.4f}\\n\");\n",
    "    f.write(f\"Micro-R   : {micro_r:.4f}\\n\");\n",
    "print((OUT_DIR/\"overall_metrics.txt\").read_text())\n",
    "\n",
    "\n",
    "# %% t-SNE Visual qualitativa\n",
    "sample_cls = 'bird chirp'      # cambia a piacere\n",
    "pairs = mi_store[sample_cls]\n",
    "if pairs:\n",
    "    X,y = pairs[0]        # primo batch\n",
    "    emb = TSNE(perplexity=30,random_state=0).fit_transform(X[:2000])\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.scatter(emb[:,0], emb[:,1], c=y[:2000], s=5)\n",
    "    plt.title(f\"t-SNE – {sample_cls}\")\n",
    "    plt.axis('off'); plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bmwTeam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
