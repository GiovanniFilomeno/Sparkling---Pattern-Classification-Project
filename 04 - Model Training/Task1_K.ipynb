{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bf11de3",
   "metadata": {},
   "source": [
    "**Task 4, Challenge**\n",
    "\n",
    "Question 1, a,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19555cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Train files: 6584\n",
      "# Eval files:  1646\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import numpy as np\n",
    "\n",
    "# Load metadata to get list of audio files (each corresponds to one feature/label file)\n",
    "metadata_df = pd.read_csv(\"metadata.csv\")\n",
    "\n",
    "# Ensure the 'filename' column exists\n",
    "assert 'filename' in metadata_df.columns, \"Expected 'filename' column in metadata.csv\"\n",
    "\n",
    "# Each filename is a unique group (e.g., '1234.mp3')\n",
    "audio_files = metadata_df['filename'].tolist()\n",
    "\n",
    "# Setup group split (80% train, 20% eval)\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "# Use file names as both X and groups\n",
    "train_idx, eval_idx = next(gss.split(audio_files, groups=audio_files))\n",
    "train_files = [audio_files[i] for i in train_idx]\n",
    "eval_files = [audio_files[i] for i in eval_idx]\n",
    "\n",
    "# Double-check no overlap\n",
    "assert set(train_files).isdisjoint(set(eval_files)), \"Leakage: some files in both splits!\"\n",
    "\n",
    "# Optional: save for later use\n",
    "pd.DataFrame({'filename': train_files}).to_csv(\"train_files.csv\", index=False)\n",
    "pd.DataFrame({'filename': eval_files}).to_csv(\"eval_files.csv\", index=False)\n",
    "\n",
    "print(f\"# Train files: {len(train_files)}\")\n",
    "print(f\"# Eval files:  {len(eval_files)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1a8f6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available classes: ['Airplane', 'Alarm', 'Beep/Bleep', 'Bell', 'Bicycle', 'Bird Chirp', 'Bus', 'Car', 'Cat Meow', 'Chainsaw', 'Clapping', 'Cough', 'Cow Moo', 'Cowbell', 'Crying', 'Dog Bark', 'Doorbell', 'Drip', 'Drums', 'Fire', 'Footsteps', 'Guitar', 'Hammer', 'Helicopter', 'Hiccup', 'Horn Honk', 'Horse Neigh', 'Insect Buzz', 'Jackhammer', 'Laughter', 'Lawn Mower', 'Motorcycle', 'Piano', 'Pig Oink', 'Power Drill', 'Power Saw', 'Rain', 'Rooster Crow', 'Saxophone', 'Sewing Machine', 'Sheep/Goat Bleat', 'Ship/Boat', 'Shout', 'Singing', 'Siren', 'Sneeze', 'Snoring', 'Speech', 'Stream/River', 'Thunder', 'Train', 'Truck', 'Trumpet', 'Vacuum Cleaner', 'Violin', 'Washing Machine', 'Waves', 'Wind']\n",
      "Shape of one class array: (166, 1)\n"
     ]
    }
   ],
   "source": [
    "labels = np.load(\"labels/14_labels.npz\")\n",
    "print(\"Available classes:\", labels.files)\n",
    "print(\"Shape of one class array:\", labels['Speech'].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3654ca54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6584, 1646)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#code with multi-label stratification to ensure balanced splits\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load metadata\n",
    "metadata_path = \"metadata.csv\"\n",
    "metadata_df = pd.read_csv(metadata_path)\n",
    "n_metadata = len(metadata_df)\n",
    "\n",
    "# Define target classes\n",
    "target_classes = ['Speech', 'Dog Bark', 'Rooster Crow', 'Shout',\n",
    "                  'Lawn Mower', 'Chainsaw', 'Jackhammer',\n",
    "                  'Power Drill', 'Horn Honk', 'Siren']\n",
    "\n",
    "# Folder containing label files\n",
    "labels_folder = \"labels\"\n",
    "\n",
    "# Gather all npz label files\n",
    "label_files = sorted([f for f in os.listdir(labels_folder) if f.endswith(\".npz\")])\n",
    "file_class_matrix = []\n",
    "all_filenames = []\n",
    "\n",
    "base_idx = 0\n",
    "\n",
    "# Iterate over label files and extract presence info\n",
    "for label_file in label_files:\n",
    "    label_path = os.path.join(labels_folder, label_file)\n",
    "    labels = np.load(label_path)\n",
    "\n",
    "    n_files = labels[target_classes[0]].shape[0]\n",
    "    file_indices = range(base_idx, base_idx + n_files)\n",
    "\n",
    "    for i, file_idx in enumerate(file_indices):\n",
    "        if file_idx >= n_metadata:\n",
    "            break\n",
    "        filename = metadata_df.loc[file_idx, \"filename\"].replace(\".mp3\", \".npz\")\n",
    "        all_filenames.append(filename)\n",
    "\n",
    "        row = []\n",
    "        for cls in target_classes:\n",
    "            presence = int(np.any(labels[cls][i]))\n",
    "            row.append(presence)\n",
    "        file_class_matrix.append(row)\n",
    "\n",
    "    base_idx += n_files\n",
    "\n",
    "# Create DataFrame for stratification\n",
    "file_class_df = pd.DataFrame(file_class_matrix, columns=target_classes)\n",
    "file_class_df[\"filename\"] = all_filenames\n",
    "file_class_df[\"strata\"] = file_class_df[target_classes].astype(str).agg(\"\".join, axis=1)\n",
    "\n",
    "# Perform stratified train-test split\n",
    "train_files, test_files = train_test_split(\n",
    "    file_class_df[\"filename\"],\n",
    "    test_size=0.2,\n",
    "    stratify=file_class_df[\"strata\"],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "len(train_files), len(test_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02654bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Load test filenames\n",
    "test_files = pd.read_csv(\"test_filenames.csv\")[\"filename\"].tolist()\n",
    "test_files = [f.replace(\".npz\", \".wav\") for f in test_files]  # Required format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed500c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random predictions for the test set\n",
    "\n",
    "import numpy as np\n",
    "from compute_cost import get_segment_prediction_df, get_ground_truth_df\n",
    "\n",
    "# Define your 10 target classes\n",
    "target_classes = ['Speech', 'Dog Bark', 'Rooster Crow', 'Shout',\n",
    "                  'Lawn Mower', 'Chainsaw', 'Jackhammer',\n",
    "                  'Power Drill', 'Horn Honk', 'Siren']\n",
    "\n",
    "# Random prediction generator\n",
    "def generate_random_predictions(test_files, dataset_path, classes):\n",
    "    predictions = {}\n",
    "    for filename in test_files:\n",
    "        feature_file = filename.replace(\".wav\", \".npz\")\n",
    "        path = f\"{dataset_path}/audio_features/{feature_file}\"\n",
    "        try:\n",
    "            n_frames = np.load(path)[\"mfcc\"].shape[0]  # Use MFCC to determine frame count\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Missing feature file: {path}\")\n",
    "            continue\n",
    "        predictions[filename] = {\n",
    "            cls: np.random.randint(0, 2, size=n_frames).tolist() for cls in classes\n",
    "        }\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56abc3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered 0 test files due to missing .npz files.\n"
     ]
    }
   ],
   "source": [
    "#create ground truth and prediction dataframes\n",
    "\n",
    "dataset_path = \"C:/Users/kathr/Documents/AI-Bachelor/MLPC/MLPC2025_classification\"\n",
    "\n",
    "import os\n",
    "\n",
    "def filter_existing_files(file_list, dataset_path):\n",
    "    valid_files = []\n",
    "    for fname in file_list:\n",
    "        base = os.path.splitext(fname)[0]\n",
    "        feat_path = os.path.join(dataset_path, 'audio_features', f\"{base}.npz\")\n",
    "        label_path = os.path.join(dataset_path, 'labels', f\"{base}_labels.npz\")\n",
    "        if os.path.exists(feat_path) and os.path.exists(label_path):\n",
    "            valid_files.append(fname)\n",
    "    return valid_files\n",
    "\n",
    "filtered_test_files = filter_existing_files(test_files, dataset_path)\n",
    "\n",
    "# Generate predictions\n",
    "random_preds = generate_random_predictions(filtered_test_files, dataset_path, target_classes)\n",
    "\n",
    "# Create and save prediction and ground truth CSVs\n",
    "get_segment_prediction_df(random_preds, target_classes).to_csv(\"predictions.csv\", index=False)\n",
    "\n",
    "get_ground_truth_df(filtered_test_files, dataset_path).to_csv(\"ground_truth.csv\", index=False)\n",
    "\n",
    "print(f\"Filtered {len(test_files) - len(filtered_test_files)} test files due to missing .npz files.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a15c866b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     filename  onset  Speech  Dog Bark  Rooster Crow  Shout  Lawn Mower  \\\n",
      "0  197321.wav    0.0       1         1             1      1           1   \n",
      "1  197321.wav    1.2       1         1             1      1           1   \n",
      "2  197321.wav    2.4       1         1             1      1           1   \n",
      "3  197321.wav    3.6       1         1             1      1           1   \n",
      "4  197321.wav    4.8       1         1             1      1           1   \n",
      "\n",
      "   Chainsaw  Jackhammer  Power Drill  Horn Honk  Siren  \n",
      "0         1           1            1          1      1  \n",
      "1         1           1            1          1      1  \n",
      "2         1           1            1          1      1  \n",
      "3         1           1            1          1      1  \n",
      "4         1           1            1          1      1  \n",
      "            onset      Speech    Dog Bark  Rooster Crow       Shout  \\\n",
      "count  647.000000  647.000000  647.000000    647.000000  647.000000   \n",
      "mean    11.261824    0.995363    0.996909      0.993818    0.998454   \n",
      "std      7.322666    0.067988    0.055555      0.078445    0.039314   \n",
      "min      0.000000    0.000000    0.000000      0.000000    0.000000   \n",
      "25%      4.800000    1.000000    1.000000      1.000000    1.000000   \n",
      "50%     10.800000    1.000000    1.000000      1.000000    1.000000   \n",
      "75%     16.800000    1.000000    1.000000      1.000000    1.000000   \n",
      "max     28.800000    1.000000    1.000000      1.000000    1.000000   \n",
      "\n",
      "       Lawn Mower    Chainsaw  Jackhammer  Power Drill   Horn Honk       Siren  \n",
      "count  647.000000  647.000000  647.000000   647.000000  647.000000  647.000000  \n",
      "mean     0.992272    0.990726    0.995363     0.995363    0.993818    0.993818  \n",
      "std      0.087636    0.095926    0.067988     0.067988    0.078445    0.078445  \n",
      "min      0.000000    0.000000    0.000000     0.000000    0.000000    0.000000  \n",
      "25%      1.000000    1.000000    1.000000     1.000000    1.000000    1.000000  \n",
      "50%      1.000000    1.000000    1.000000     1.000000    1.000000    1.000000  \n",
      "75%      1.000000    1.000000    1.000000     1.000000    1.000000    1.000000  \n",
      "max      1.000000    1.000000    1.000000     1.000000    1.000000    1.000000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pred_df = pd.read_csv(\"predictions.csv\")\n",
    "print(pred_df.head())\n",
    "print(pred_df.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d28606d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_all_zero_predictions(test_files, dataset_path, target_classes):\n",
    "    predictions = {}\n",
    "    for fname in test_files:\n",
    "        base = os.path.splitext(fname)[0]\n",
    "        feat_path = os.path.join(dataset_path, \"audio_features\", f\"{base}.npz\")\n",
    "        with np.load(feat_path) as data:\n",
    "            n_segments = data[\"mfcc\"].shape[0]\n",
    "        predictions[fname] = {cls: [0] * n_segments for cls in target_classes}\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c3d7639",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_all_one_predictions(test_files, dataset_path, target_classes):\n",
    "    predictions = {}\n",
    "    for fname in test_files:\n",
    "        base = os.path.splitext(fname)[0]\n",
    "        feat_path = os.path.join(dataset_path, \"audio_features\", f\"{base}.npz\")\n",
    "        with np.load(feat_path) as data:\n",
    "            n_segments = data[\"mfcc\"].shape[0]\n",
    "        predictions[fname] = {cls: [1] * n_segments for cls in target_classes}\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67cbd4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose one (all zeros or all ones):\n",
    "#preds = generate_all_zero_predictions(test_files, dataset_path, target_classes)\n",
    "preds = generate_all_one_predictions(test_files, dataset_path, target_classes)\n",
    "\n",
    "# Save predictions and ground truth\n",
    "get_segment_prediction_df(preds, target_classes).to_csv(\"predictions.csv\", index=False)\n",
    "get_ground_truth_df(test_files, dataset_path).to_csv(\"ground_truth.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
